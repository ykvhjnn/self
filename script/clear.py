import sys
import asyncio

# å¸¸ç”¨åŠè§„èŒƒçš„é¡¶çº§åŸŸåï¼ˆTLDï¼‰é›†åˆï¼ŒåŒ…å«å¸¸è§å•çº§å’Œå¤šçº§TLDï¼Œéƒ¨åˆ†IDNç¼–ç TLD
# å¦‚éœ€æ›´å…¨TLDå¯ä» https://publicsuffix.org/list/public_suffix_list.dat åŠ¨æ€åŠ è½½
COMMON_TLDS = {
    # é€šç”¨é¡¶çº§åŸŸ
    "com", "org", "net", "edu", "gov", "mil", "int", "biz", "info", "name", "pro", "coop", "aero", "museum", "idv", "xyz", "top", "site", "online", "club", "shop", "app", "io", "dev", "art", "inc", "vip", "store", "tech", "blog", "wiki", "link", "live", "news", "run", "fun", "cloud", "one", "world", "group", "life", "today", "agency", "company", "center", "team", "email", "solutions", "network", "systems", "media", "digital", "works", "design", "finance", "plus", "studio",
    # å›½å®¶å’Œåœ°åŒºé¡¶çº§åŸŸ
    "cn", "us", "uk", "jp", "de", "fr", "ru", "au", "ca", "br", "it", "es", "nl", "se", "ch", "no", "fi", "be", "at", "dk", "pl", "hk", "tw", "kr", "in", "sg", "cz", "il", "ie", "tr", "za", "mx", "cl", "ar", "nz", "gr", "hu", "pt", "ro", "bg", "sk", "si", "lt", "lv", "ee", "hr", "rs", "ua", "by", "kz", "ge", "md", "ba", "al", "me", "is", "lu", "li", "mt", "cy", "mc", "sm", "ad", "va",
    # å¸¸è§å¤šçº§TLDï¼ˆä¸­å›½åŠéƒ¨åˆ†å›½å®¶ï¼‰
    "com.cn", "net.cn", "gov.cn", "org.cn", "edu.cn", "ac.cn", "bj.cn", "sh.cn", "tj.cn", "cq.cn", "he.cn", "nm.cn", "ln.cn", "jl.cn", "hl.cn", "js.cn", "zj.cn", "ah.cn", "fj.cn", "jx.cn", "sd.cn", "ha.cn", "hb.cn", "hn.cn", "gd.cn", "gx.cn", "hi.cn", "sc.cn", "gz.cn", "yn.cn", "xz.cn", "sn.cn", "gs.cn", "qh.cn", "nx.cn", "xj.cn",
    # å›½é™…åŒ–åŸŸåTLDï¼ˆIDNï¼‰
    "xn--fiqs8s", "xn--fiqz9s", "xn--55qx5d", "xn--io0a7i",
    # è‹±è”é‚¦å¸¸ç”¨TLD
    "co.uk", "org.uk", "gov.uk", "ac.uk", "sch.uk",
    # æ¾³å¤§åˆ©äºš
    "com.au", "net.au", "org.au", "edu.au", "gov.au", "asn.au", "id.au",
    # åŠ æ‹¿å¤§
    "ca",
    # æ–°è¥¿å…°
    "co.nz", "ac.nz", "geek.nz", "maori.nz", "net.nz", "org.nz", "school.nz", "govt.nz", "parliament.nz", "cri.nz", "health.nz", "iwi.nz", "kiwi.nz", "mil.nz",
    # å…¶ä»–å¸¸è§å¤šçº§TLD
    "co.jp", "ne.jp", "or.jp", "go.jp", "ac.jp", "ed.jp", "gr.jp", "lg.jp",
    "com.hk", "net.hk", "org.hk", "idv.hk", "gov.hk", "edu.hk"
}

def filter_parent_domains(domains: set[str]) -> set[str]:
    """
    è¿‡æ»¤æ‰å±äºçˆ¶åŸŸåçš„å­åŸŸåï¼Œåªä¿ç•™æœ€é¡¶å±‚çš„åŸŸåã€‚
    ä¾‹å¦‚ï¼Œä¿ç•™ a.comï¼Œè¿‡æ»¤æ‰ b.a.comã€‚
    :param domains: åŸŸåé›†åˆ
    :return: ç­›é€‰åçš„åŸŸåé›†åˆ
    """
    sorted_domains = sorted(domains, key=lambda d: d[::-1])
    result = []
    for domain in sorted_domains:
        if not result or not domain.endswith("." + result[-1]):
            result.append(domain)
    return set(result)

def extract_full_tld(parts):
    """
    ä»åŸŸååˆ†æ®µä¸­ï¼Œæå–æœ€é•¿åŒ¹é…çš„é¡¶çº§åŸŸåï¼ˆæ”¯æŒå¤šçº§TLDï¼‰ã€‚
    :param parts: åŸŸååˆ†æ®µåˆ—è¡¨
    :return: (ä¸»åŸŸéƒ¨åˆ†, å®Œæ•´TLD)
    """
    # æœ€å¤šæ”¯æŒ4çº§TLDï¼ˆå¦‚ gov.uk, com.cn, co.jp, ä½†ä¸ä¼šè¶…å‡ºæ­¤èŒƒå›´ï¼‰
    for i in range(4, 0, -1):
        if len(parts) >= i:
            tld = ".".join(parts[-i:]).lower()
            if tld in COMMON_TLDS:
                return parts[:-i], tld
    # æœªåŒ¹é…åˆ°åˆ™æœ€åä¸€çº§ä½œä¸ºTLD
    return parts[:-1], parts[-1].lower() if parts else ""

def sort_key_ignore_tld(domain: str):
    """
    åŸŸåæ’åºå…³é”®å­—ç”Ÿæˆå‡½æ•°ï¼Œæ’åºæ—¶å¿½ç•¥å®Œæ•´TLDï¼ŒåªæŒ‰ä¸»åŸŸå’Œå­åŸŸæ’åºï¼ŒTLDä»…åœ¨ä¸»åŸŸå®Œå…¨ç›¸åŒæ—¶æ‰å‚ä¸æ’åºã€‚
    :param domain: åŸŸåå­—ç¬¦ä¸²
    :return: æ’åºæ‰€ç”¨çš„å…ƒç»„ï¼ˆä¿è¯é•¿åº¦ä¸€è‡´ï¼Œé¿å…TypeErrorï¼‰
    """
    parts = domain.strip().split('.')
    if not parts or not any(parts):
        # ä¿è¯è¿”å›å››å…ƒç»„
        return ("", "", "", 0)
    rest, tld = extract_full_tld(parts)
    # ä¿è¯è¿”å›é•¿åº¦ä¸€è‡´çš„å…ƒç»„ï¼ˆä¸»åŸŸã€æ¬¡ä¸»åŸŸã€å­åŸŸã€TLDã€æ€»é•¿åº¦ï¼‰
    max_rest_len = 3  # æœ€å¤šä¿ç•™3çº§å­åŸŸ
    rest_parts = list(rest[::-1])
    while len(rest_parts) < max_rest_len:
        rest_parts.append('')
    return (*rest_parts[:max_rest_len], tld, len(parts))

async def read_lines(file_path: str, chunk_size: int = 10000):
    """
    å¼‚æ­¥åˆ†å—è¯»å–æ–‡ä»¶ï¼ŒèŠ‚çœå†…å­˜ï¼Œæé«˜å¤§æ–‡ä»¶å¤„ç†æ•ˆç‡ã€‚
    :param file_path: æ–‡ä»¶è·¯å¾„
    :param chunk_size: æ¯æ¬¡è¯»å–çš„æœ€å¤§å­—ç¬¦æ•°
    """
    try:
        with open(file_path, "r", encoding="utf8") as f:
            while True:
                lines = f.readlines(chunk_size)
                if not lines:
                    break
                yield lines
    except FileNotFoundError:
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return

def process_chunk(chunk: list[str]) -> set[str]:
    """
    å¤„ç†è¯»å–åˆ°çš„æ¯ä¸ªå—ï¼Œå»é™¤ç©ºè¡ŒåŠç©ºç™½å­—ç¬¦ï¼Œå¹¶è½¬ä¸ºé›†åˆå»é‡ã€‚
    :param chunk: è¡Œåˆ—è¡¨
    :return: å»é‡åçš„åŸŸåé›†åˆ
    """
    return set(line.strip() for line in chunk if line.strip())

async def main():
    """
    ä¸»ç¨‹åºå…¥å£ï¼Œä¾æ¬¡å®Œæˆæ–‡ä»¶è¯»å–ã€å»é‡ã€çˆ¶åŸŸåè¿‡æ»¤ã€è§„èŒƒæ’åºåŠç»“æœå†™å›ã€‚
    é¿å…æ‰€æœ‰å¸¸è§é”™è¯¯ï¼Œé‡åˆ°å¼‚å¸¸æ—¶å‹å¥½æç¤ºã€‚
    """
    try:
        if len(sys.argv) < 2:
            print("è¯·æä¾›è¾“å…¥æ–‡ä»¶è·¯å¾„ä½œä¸ºå‚æ•°")
            return
        file_name = sys.argv[1]
        all_domains = set()
        # è¯»å–æ–‡ä»¶å¹¶å»é‡
        async for chunk in read_lines(file_name):
            all_domains.update(process_chunk(chunk))
        if not all_domains:
            print("æ–‡ä»¶ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ã€‚")
            return
        # è¿‡æ»¤çˆ¶åŸŸå
        filtered_domains = filter_parent_domains(all_domains)
        # æ’åºï¼Œå¿½ç•¥å®Œæ•´TLD
        sorted_domains = sorted(filtered_domains, key=sort_key_ignore_tld)
        # å†™å›æ–‡ä»¶ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        try:
            with open(file_name, "w", encoding="utf8") as f:
                for domain in sorted_domains:
                    f.write(f"{domain}\n")
            print(f"ğŸ’°å»é‡å®Œæˆï¼Œæœ€ç»ˆè§„åˆ™æ•°ï¼š{len(filtered_domains)}")
        except Exception as e:
            print(f"å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    except Exception as e:
        print("å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
