import sys
import asyncio

# å¸¸ç”¨åŠè§„èŒƒçš„é¡¶çº§åŸŸåï¼ˆTLDï¼‰é›†åˆ
COMMON_TLDS = {
    # é€šç”¨TLD
    "com", "org", "net", "edu", "gov", "mil", "int", "biz", "info", "name", "pro", "coop", "aero", "museum", "idv", "xyz", "top", "site", "online", "club", "shop", "app", "io", "dev", "art", "inc", "vip", "store", "tech", "blog", "wiki", "link", "live", "news", "run", "fun", "cloud", "one", "world", "group", "life", "today", "agency", "company", "center", "team", "email", "solutions", "network", "systems", "media", "digital", "works", "design", "finance", "plus", "studio",
    # å›½å®¶å’Œåœ°åŒºTLD
    "cn", "us", "uk", "jp", "de", "fr", "ru", "au", "ca", "br", "it", "es", "nl", "se", "ch", "no", "fi", "be", "at", "dk", "pl", "hk", "tw", "kr", "in", "sg", "cz", "il", "ie", "tr", "za", "mx", "cl", "ar", "nz", "gr", "hu", "pt", "ro", "bg", "sk", "si", "lt", "lv", "ee", "hr", "rs", "ua", "by", "kz", "ge", "md", "ba", "al", "me", "is", "lu", "li", "mt", "cy", "mc", "sm", "ad", "va",
    # å¤šçº§TLDï¼ˆä¸­å›½åŠéƒ¨åˆ†å›½å®¶ï¼‰
    "com.cn", "net.cn", "gov.cn", "org.cn", "edu.cn", "ac.cn", "bj.cn", "sh.cn", "tj.cn", "cq.cn", "he.cn", "nm.cn", "ln.cn", "jl.cn", "hl.cn", "js.cn", "zj.cn", "ah.cn", "fj.cn", "jx.cn", "sd.cn", "ha.cn", "hb.cn", "hn.cn", "gd.cn", "gx.cn", "hi.cn", "sc.cn", "gz.cn", "yn.cn", "xz.cn", "sn.cn", "gs.cn", "qh.cn", "nx.cn", "xj.cn",
    # è‹±è”é‚¦/å…¶ä»–å¸¸ç”¨å¤šçº§TLD
    "co.uk", "org.uk", "gov.uk", "ac.uk", "sch.uk",
    "com.au", "net.au", "org.au", "edu.au", "gov.au", "asn.au", "id.au",
    "co.jp", "ne.jp", "or.jp", "go.jp", "ac.jp", "ed.jp", "gr.jp", "lg.jp",
    "com.hk", "net.hk", "org.hk", "idv.hk", "gov.hk", "edu.hk",
    "co.nz", "ac.nz", "geek.nz", "maori.nz", "net.nz", "org.nz", "school.nz", "govt.nz",
    # å›½é™…åŒ–åŸŸåTLDï¼ˆIDNï¼‰
    "xn--fiqs8s", "xn--fiqz9s", "xn--55qx5d", "xn--io0a7i",
}

def extract_full_tld(parts):
    """
    ä»åŸŸååˆ†æ®µä¸­ï¼Œæå–æœ€é•¿åŒ¹é…çš„é¡¶çº§åŸŸåï¼ˆæ”¯æŒå¤šçº§TLDï¼‰ã€‚
    :param parts: åŸŸååˆ†æ®µåˆ—è¡¨
    :return: (ä¸»åŸŸéƒ¨åˆ†, å®Œæ•´TLD)
    """
    for i in range(4, 0, -1):
        if len(parts) >= i:
            tld = ".".join(parts[-i:]).lower()
            if tld in COMMON_TLDS:
                return parts[:-i], tld
    return parts[:-1], parts[-1].lower() if parts else ""

def sort_key_ignore_tld(domain: str):
    """
    åŸŸåæ’åºå…³é”®å­—ç”Ÿæˆå‡½æ•°ï¼Œæ’åºæ—¶å¿½ç•¥å®Œæ•´TLDï¼ŒåªæŒ‰ä¸»åŸŸå’Œå­åŸŸæ’åºï¼ŒTLDä»…åœ¨ä¸»åŸŸå®Œå…¨ç›¸åŒæ—¶æ‰å‚ä¸æ’åºã€‚
    """
    parts = domain.strip().split('.')
    if not parts or not any(parts):
        return ("", "", "", 0)
    rest, tld = extract_full_tld(parts)
    max_rest_len = 3
    rest_parts = list(rest[::-1])
    while len(rest_parts) < max_rest_len:
        rest_parts.append('')
    return (*rest_parts[:max_rest_len], tld, len(parts))

def process_chunk(chunk: list[str]) -> set[str]:
    """
    å¤„ç†è¯»å–åˆ°çš„æ¯ä¸ªå—ï¼Œå»é™¤ç©ºè¡ŒåŠç©ºç™½å­—ç¬¦ï¼Œå¹¶è½¬ä¸ºå°å†™é›†åˆå»é‡ã€‚
    """
    return set(line.strip().lower() for line in chunk if line.strip())

def normalize_domain(domain: str):
    """
    è§„èŒƒåŒ–åŸŸåï¼Œç§»é™¤å¤šä½™ç‚¹å·å’Œç©ºç™½ï¼Œå…¨éƒ¨å°å†™ã€‚
    """
    return domain.strip().strip('.').lower()

def filter_parent_domains_fast(domains: set[str]) -> set[str]:
    """
    é«˜æ•ˆçˆ¶åŸŸåå»é‡é€»è¾‘ï¼šä¿ç•™æœ€é•¿çš„å­åŸŸï¼Œå»é™¤å…¶æ‰€æœ‰ç¥–å…ˆåŸŸåã€‚
    é‡‡ç”¨Trieç»“æ„ï¼ŒO(N*L)ã€‚
    """
    class TrieNode:
        __slots__ = ['children', 'is_end']
        def __init__(self):
            self.children = dict()
            self.is_end = False

    root = TrieNode()
    domains_sorted = sorted(domains, key=lambda d: (-len(d), d))  # é•¿çš„åœ¨å‰
    result = set()

    for domain in domains_sorted:
        parts = domain.split('.')
        node = root
        new_branch = False
        # é€†åºæ’å…¥Trieï¼Œé¡¶çº§åŸŸåœ¨æ ¹
        for part in reversed(parts):
            if part not in node.children:
                node.children[part] = TrieNode()
                new_branch = True
            node = node.children[part]
            # å¦‚æœæŸç¥–å…ˆå·²æ ‡è®°ä¸ºendï¼Œå½“å‰åŸŸåæ˜¯å…¶å­åŸŸï¼Œåº”è·³è¿‡
            if node.is_end:
                new_branch = False
                break
        if new_branch:
            node.is_end = True
            result.add(domain)
    return result

async def read_lines(file_path: str, chunk_size: int = 100000):
    """
    åˆ†å—å¼‚æ­¥è¯»å–æ–‡ä»¶ï¼ŒèŠ‚çœå†…å­˜ï¼Œæé«˜å¤§æ–‡ä»¶å¤„ç†æ•ˆç‡ã€‚
    """
    try:
        with open(file_path, "r", encoding="utf8") as f:
            while True:
                lines = f.readlines(chunk_size)
                if not lines:
                    break
                yield lines
    except FileNotFoundError:
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return

async def main():
    """
    ä¸»ç¨‹åºå…¥å£ï¼Œå®Œæˆæ–‡ä»¶è¯»å–ã€å»é‡ã€çˆ¶åŸŸåè¿‡æ»¤ã€æ’åºå’Œå†™å›ï¼Œç¡®ä¿å¥å£®æ€§å’Œé«˜æ•ˆæ€§ã€‚
    """
    try:
        if len(sys.argv) < 2:
            print("è¯·æä¾›è¾“å…¥æ–‡ä»¶è·¯å¾„ä½œä¸ºå‚æ•°")
            return
        file_name = sys.argv[1]
        all_domains = set()
        async for chunk in read_lines(file_name):
            all_domains.update(process_chunk(chunk))
        if not all_domains:
            print("æ–‡ä»¶ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ã€‚")
            return
        # äºŒæ¬¡è§„èŒƒåŒ–ï¼Œå½»åº•ç§»é™¤é‡å¤ç‚¹å·ç­‰å¼‚å¸¸
        all_domains = set(normalize_domain(d) for d in all_domains if d)
        # é«˜æ•ˆçˆ¶åŸŸåå»é‡
        filtered_domains = filter_parent_domains_fast(all_domains)
        sorted_domains = sorted(filtered_domains, key=sort_key_ignore_tld)
        try:
            with open(file_name, "w", encoding="utf8") as f:
                for domain in sorted_domains:
                    f.write(f"{domain}\n")
            print(f"ğŸ’°å»é‡å®Œæˆï¼Œæœ€ç»ˆè§„åˆ™æ•°ï¼š{len(filtered_domains)}")
        except Exception as e:
            print(f"å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    except Exception as e:
        print("å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
